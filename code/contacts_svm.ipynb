{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bmukund/miniconda3/lib/python3.8/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package wordnet to /Users/bmukund/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/bmukund/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%timeit\n",
    "import sys\n",
    "sys.path.append('pymodules')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# this class read the raw input and tokenizes comprehensively for use with modeling\n",
    "import pymodules.read_and_tokenize as contacts_utils\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "#from sklearn.metrics import multilabel_confusion_matrix, f1_score\n",
    "## multiprocessing\n",
    "#import multiprocess as mp\n",
    "## not sure if this is needed, although used below ...\n",
    "#from keras.utils import to_categorical\n",
    "## from https://stackoverflow.com/questions/7370801/how-do-i-measure-elapsed-time-in-python\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped: ['OVERALL_RATING', 'COMFORT_RATING', 'VISION_RATING', 'VALUE_FOR_MONEY', 'PROS', 'CONS', 'ORIGINAL_SOURCE', 'REPLY_FROM_ACCUVUE', 'PRODUCT_LINK', 'WEBSITE']\n",
      "Read sheet 'Scrubbed_data' ...\n",
      " Drop the Author column and replace it with gender of author ...\n",
      "Consolidate all the comments into one column called COMMENT\n",
      "Make ratings into integers\n",
      "Tokenize data based on regex found from experimentation and common usage ...\n",
      "Comments before tokenization at index[0]:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments after tokenization at index[0]:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] before basic cleaning:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] after cleaning:\n",
      " acucue 2 contact lenses i have used these lenses for a long time and i have to say that the service from lens.com is great and the lenses work great for my needs!  i highly recommend them!\n",
      "Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "\n",
      "['acucue', '2', 'contact', 'lenses', 'i', 'have', 'used', 'these', 'lenses', 'for', 'a', 'long', 'time', 'and', 'i', 'have', 'to', 'say', 'that', 'the', 'service', 'from', 'lens', '.', 'com', 'is', 'great', 'and', 'the', 'lenses', 'work', 'great', 'for', 'my', 'needs', '!', 'i', 'highly', 'recommend', 'them', '!']\n",
      "Comments at index[0] before removal of punctuations:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] after removal of punctuation:\n",
      " ['acucue', 'contact', 'lenses', 'have', 'used', 'these', 'lenses', 'for', 'long', 'time', 'and', 'have', 'say', 'that', 'the', 'service', 'from', 'lens', 'com', 'great', 'and', 'the', 'lenses', 'work', 'great', 'for', 'needs', 'highly', 'recommend', 'them']\n",
      "Comments at index[0] before removal of stop words:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] after removal of stop words:\n",
      " ['acucue', 'contact', 'lenses', 'used', 'lenses', 'time', 'service', 'lens', 'com', 'great', 'lenses', 'work', 'great', 'needs', 'highly', 'recommend']\n",
      "Lemmatize tokens\n",
      "Comments at index[0] after lemmatization:\n",
      " ['acucue', 'contact', 'lense', 'use', 'lense', 'time', 'service', 'lens', 'com', 'great', 'lense', 'work', 'great', 'need', 'highly', 'recommend']\n",
      "Build the bigram and trigram words for use with topic modeling\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/Master-data_Q42021.xlsx\"\n",
    "prep_comments, df = contacts_utils.read_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vectorization\n",
    "* TF-IDF weights more words that occur frequently but in lesser number of documents. This seems to skew ranking towards advertisement like reviews. In any case for SVM, we use the count of tokens to establish a baseline accuracy of model, prior to using RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# simple auxiliary function to override the preprocessing done by sklearn\n",
    "def do_nothing(doc):\n",
    "    return doc\n",
    "\n",
    "# create a CountVectorizer object using our preprocessed text\n",
    "# uni gram\n",
    "count_vectorizer = CountVectorizer(encoding='utf-8',\n",
    "                                   preprocessor=do_nothing,  # apply no additional preprocessing\n",
    "                                   tokenizer=do_nothing,     # apply no additional tokenization\n",
    "                                   lowercase=False,\n",
    "                                   strip_accents=None,\n",
    "                                   stop_words=None,\n",
    "                                   ngram_range=(1, 1),       # generate only unigrams\n",
    "                                   analyzer='word',          # analysis at the word-level\n",
    "                                   max_df=0.5,              # ignore tokens that have a higher document frequency (can be int or percent)\n",
    "                                   min_df=500,                # ignore tokens that have a lowe document frequency (can be int or percent)\n",
    "                                   max_features=None,        # we could impose a maximum number of vocabulary terms\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-term matrix created with shape: (8794, 18)\n"
     ]
    }
   ],
   "source": [
    "# transform our preprocessed tokens into a document-term matrix\n",
    "dt_matrix = count_vectorizer.fit_transform(prep_comments.tokens)\n",
    "print(f\"Document-term matrix created with shape: {dt_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              0   1\n0       contact   1\n1        lenses  10\n2       service  15\n3          lens   9\n4         great   8\n5   comfortable   0\n6          easy   4\n7       product  14\n8         years  17\n9          fast   6\n10     contacts   2\n11          day   3\n12         pack  12\n13         eyes   5\n14         love  11\n15         good   7\n16        price  13\n17         wear  16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>contact</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>lenses</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>service</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lens</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>great</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>comfortable</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>easy</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>product</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>years</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fast</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>contacts</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>day</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pack</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>eyes</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>love</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>good</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>price</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>wear</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can access a dictionary that maps between words and positions of the document-term matrix. We need this for SVM in order to make the word itself as column of dataframe (see output)\n",
    "id_word_indexer = pd.DataFrame(count_vectorizer.vocabulary_.items())\n",
    "id_word_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      contact  lenses  service  lens  great  comfortable  easy  product  \\\n0           0       1        0     0      0            0     0        0   \n1           0       0        0     0      0            0     0        0   \n2           1       0        0     0      0            0     0        0   \n3           0       0        0     0      1            0     0        0   \n4           0       0        0     0      0            0     0        0   \n...       ...     ...      ...   ...    ...          ...   ...      ...   \n8789        0       0        0     0      0            0     1        0   \n8790        2       0        0     0      0            0     0        1   \n8791        2       0        0     0      0            0     0        0   \n8792        0       1        2     0      0            3     0        0   \n8793        0       0        0     0      0            0     1        0   \n\n      years  fast  contacts  day  pack  eyes  love  good  price  wear  \n0         2     1         3    0     0     0     0     1      0     0  \n1         0     0         0    0     0     0     0     0      0     0  \n2         0     0         0    0     0     0     0     0      0     0  \n3         0     0         0    0     0     0     1     0      0     1  \n4         0     0         0    0     0     0     0     0      0     0  \n...     ...   ...       ...  ...   ...   ...   ...   ...    ...   ...  \n8789      0     0         0    0     0     1     0     0      0     0  \n8790      0     0         0    0     0     0     0     0      1     0  \n8791      0     0         0    0     0     0     0     0      0     0  \n8792      0     0         2    0     0     1     1     0      0     1  \n8793      0     0         0    0     0     0     0     0      0     0  \n\n[8794 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contact</th>\n      <th>lenses</th>\n      <th>service</th>\n      <th>lens</th>\n      <th>great</th>\n      <th>comfortable</th>\n      <th>easy</th>\n      <th>product</th>\n      <th>years</th>\n      <th>fast</th>\n      <th>contacts</th>\n      <th>day</th>\n      <th>pack</th>\n      <th>eyes</th>\n      <th>love</th>\n      <th>good</th>\n      <th>price</th>\n      <th>wear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8789</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8790</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8791</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8792</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8793</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8794 rows Ã— 18 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FOR SVM, we need to make a matrix with proper column names\n",
    "# Also, we need another column that denotes the review\n",
    "# We also need to normalize the data\n",
    "df_svm = pd.DataFrame(dt_matrix.toarray())\n",
    "df_svm.rename(columns=id_word_indexer.to_dict()[0], inplace=True)\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2    8386\n0     336\n1      72\nName: _SENTIMENT_, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attach sentiment, seems\n",
    "def find_sentiment(rating):\n",
    "    choices = [0, 1, 2]\n",
    "    conditions = [rating < 3, rating == 3, rating > 3]\n",
    "    senti = np.select(conditions, choices)\n",
    "    return senti\n",
    "\n",
    "SENTIMENT_SERIES = df['RATING'].apply(find_sentiment).astype('category')\n",
    "df_svm['_SENTIMENT_'] = SENTIMENT_SERIES.values\n",
    "df_svm['_SENTIMENT_'] = df_svm['_SENTIMENT_'].astype('category')\n",
    "df_svm._SENTIMENT_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df_svm.drop(['_SENTIMENT_'], axis=1)\n",
    "y = df_svm['_SENTIMENT_']\n",
    "validation_reqd = True\n",
    "df_trainX, df_trainy, df_testX, df_testy, df_validX, df_validy = contacts_utils.split_data(X, y, validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Null accuracy\n",
    "This is the accuracy based on the proportion of input distribution of sentiment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy of sentiment rating < 3, corresponding to code 0 is: 3.821%\n",
      "Null accuracy of sentiment rating = 3, corresponding to code 0 is: 0.819%\n",
      "Null accuracy of sentiment rating > 3, corresponding to code 0 is: 95.36%\n"
     ]
    }
   ],
   "source": [
    "rating_counts = y.value_counts()\n",
    "dn = np.sum(rating_counts)\n",
    "\n",
    "null_rating_lt_3 = round((rating_counts[0]/dn)* 100, 3)\n",
    "null_rating_eq_3 = round((rating_counts[1]/dn)* 100, 3)\n",
    "null_rating_gt_3 = round((rating_counts[2]/dn)* 100, 3)\n",
    "print(f\"Null accuracy of sentiment rating < 3, corresponding to code 0 is: {null_rating_lt_3}%\")\n",
    "print(f\"Null accuracy of sentiment rating = 3, corresponding to code 0 is: {null_rating_eq_3}%\")\n",
    "print(f\"Null accuracy of sentiment rating > 3, corresponding to code 0 is: {null_rating_gt_3}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Normalize column data please ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "df_trainX = ss.fit_transform(df_trainX)\n",
    "df_testX = ss.fit_transform(df_testX)\n",
    "df_validX = ss.fit_transform(df_validX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167\n",
    "# How to choose C and gamma values ...\n",
    "# 0.0001 < gamma < 10\n",
    "# 0.1 < C < 100\n",
    "# When gamma is large, C does not matter ...\n",
    "\n",
    "def create_svm_model(trainX, trainy, validX, validy):\n",
    "    def _create_svm_model(param_dict):\n",
    "        C = param_dict['C']\n",
    "        kernel = param_dict['kernel']\n",
    "        degree = param_dict['degree']\n",
    "\n",
    "        model = SVC(C=C,\n",
    "                        kernel=kernel,\n",
    "                        degree=degree,\n",
    "                        gamma='auto',\n",
    "                        class_weight='balanced',\n",
    "                        random_state=42)\n",
    "\n",
    "\n",
    "        # fit model ...\n",
    "        history = model.fit(X=trainX, y=trainy)\n",
    "            #, validation_data = (validX,validy),\n",
    "            #                verbose=1,\n",
    "            #                workers=4,\n",
    "            #                use_multiprocessing=True)\n",
    "\n",
    "        y_pred_train = model.predict(trainX)#, workers=4, use_multiprocessing=True)\n",
    "        y_pred_validation = model.predict(validX)#, workers=4, use_multiprocessing=True)\n",
    "\n",
    "        #y_train_pred_labels = convert_prob_to_labels(y_pred_train)\n",
    "        #y_validation_pred_labels = convert_prob_to_labels(y_pred_validation)\n",
    "\n",
    "        # accuracy score used ...\n",
    "        train_score = accuracy_score(trainy, y_pred_train)\n",
    "        val_score = accuracy_score(validy, y_pred_validation)\n",
    "\n",
    "        return train_score, val_score, param_dict, history, y_pred_validation\n",
    "\n",
    "    return _create_svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters to be varied\n",
    "C = [1.0] #np.logspace(0, 1, 21)\n",
    "kernel_functions = ['linear'] #('linear', 'poly', 'rbf', 'sigmoid')\n",
    "degree_vals = [1]\n",
    "\n",
    "parameters = [{'C': C,\n",
    "              'kernel': kernel_functions,\n",
    "              'degree': degree_vals\n",
    "              }\n",
    "              ]\n",
    "\n",
    "# make a grid out of parameter choices ...\n",
    "grid_params = ParameterGrid(parameters)\n",
    "[print(x) for x in grid_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to finish best parameter search with SVM model: 0.04763269876666669 mins.\n"
     ]
    }
   ],
   "source": [
    "# func that sets up the context .. i.e. what the pipeline does, what the data input is\n",
    "svm_model_func = create_svm_model(df_trainX, df_trainy, df_validX, df_validy)\n",
    "\n",
    "st_ = timer()\n",
    "# run NN model in parallel and extract results (train_score, valid_score,parameter, history of fit) as a list\n",
    "results = contacts_utils.run_parallel(svm_model_func, num_cpus=4)(grid_params)\n",
    "\n",
    "end_ = timer()\n",
    "\n",
    "print(f\"Time taken to finish best parameter search with SVM model: {(end_-st_)/60.0} mins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Why SVM ? Why not LR, Naive Bayes as NULL model ?\n",
    "* LR ans SVM are closesly related. If the idea is to know the probabilities, then LR is a good option. But if the idea is to make the *right decision* (i.e. can be expressed as ratio of likelihoods), we end up with SVM method!\n",
    "* Naive Bayes assumes *class conditional independence*. In this context, this means, given the sentiments, the features found are independent of each other. This i not true for this problem.\n",
    "* LDA is very closely related to Naive Bayes with additional assumption of Gaussian distribution of features. So we can ignore this as well.\n",
    "* What about decision trees and its friends ?\n",
    "    * No proabilistic distribution assumption on response or features\n",
    "    * Can be used in offline mode, but with addition of new data, one needs to retrain from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.49534977759805904,\n  0.40873256519102485,\n  {'C': 1.0, 'degree': 1, 'kernel': 'linear'},\n  SVC(class_weight='balanced', degree=1, gamma='auto', kernel='linear',\n      random_state=42),\n  array([0, 1, 0, ..., 0, 0, 2]))]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score:0.40873256519102485\n",
      "Best params based on validation score:{'C': 1.0, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters based on validation score\n",
    "best_validation_score = results[0][1]\n",
    "best_params = results[0][2]\n",
    "plot_data = results[0][3]\n",
    "best_validation_data = results[0][4]\n",
    "for i in range(1, len(results)):\n",
    "    tscore = results[i][0]\n",
    "    vscore = results[i][1]\n",
    "    param = results[i][2]\n",
    "    if vscore > best_validation_score:\n",
    "        best_validation_score = vscore\n",
    "        best_params = param\n",
    "        plot_data = results[i][3]\n",
    "        best_validation_data = results[i][4]\n",
    "\n",
    "# output result\n",
    "print(f\"Best validation score:{best_validation_score}\")\n",
    "print(f\"Best params based on validation score:{best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.04      0.25      0.06        32\n",
      "     neutral       0.01      0.67      0.01         6\n",
      "    positive       0.99      0.41      0.58      1611\n",
      "\n",
      "    accuracy                           0.41      1649\n",
      "   macro avg       0.34      0.44      0.22      1649\n",
      "weighted avg       0.97      0.41      0.57      1649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "targetnames=['negative', 'neutral', 'positive']\n",
    "#y_pred =   np.argmax(y_pred_raw, axis = 1)\n",
    "#y_true = np.argmax(y_test, axis = 1)\n",
    "print(metrics.classification_report(df_validy, best_validation_data, target_names=targetnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8  17   7]\n",
      " [  1   4   1]\n",
      " [207 742 662]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# multi-label plot ...\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(df_validy, best_validation_data)\n",
    "print(cm)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multi label stats\n",
    "This function extracts Accuracy, Sensitivity, Specificity and Likelihood ratio for each of the 3 sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model(<3, = 3, >3) is:   [85.93 53.85 41.96]%\n",
      "Sensitivity of the test(<3, = 3, >3):[25.   66.67 41.09]%\n",
      "Specificity of the test(<3, = 3, >3):[87.14 53.8  78.95]%\n",
      "Likelihood ratio(<3, = 3, >3):       [1.94 1.44 1.95]\n"
     ]
    }
   ],
   "source": [
    "accuracy, sensitivity, specificity, likelihood = contacts_utils.model_stats_all_labels(best_validation_data, df_validy)\n",
    "print(f'Accuracy of model(<3, = 3, >3) is:   {np.round(accuracy*100, 2)}%')\n",
    "print(f'Sensitivity of the test(<3, = 3, >3):{np.round(sensitivity*100,2)}%')\n",
    "print(f'Specificity of the test(<3, = 3, >3):{np.round(specificity*100,2)}%')\n",
    "print(f'Likelihood ratio(<3, = 3, >3):       {np.round(likelihood, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(6595, 18), y=(6595,)\n",
      "Test: X=(2199, 18), y=(2199,)\n",
      "Accuracy of model(<3, = 3, >3) is:[83.17 53.43 40.97]%\n",
      "Sensitivity of the test(<3, = 3, >3):[30.12 72.22 38.85]%\n",
      "Specificity of the test(<3, = 3, >3):[85.26 53.28 85.15]%\n",
      "Likelihood ratio(<3, = 3, >3):[2.04 1.55 2.62]\n"
     ]
    }
   ],
   "source": [
    "# We extract the best params from above cells\n",
    "best_model_params = best_params\n",
    "\n",
    "# Instead of joining validation data and train data, we simply reload the original data and split then into\n",
    "# train and test. This is suboptimal, but being relatively fast, this is ok for now\n",
    "validation_reqd = False\n",
    "# we want the output to be onehot encoded and this makes it easier to use other activation functions\n",
    "# other than softmax for the last layer, (as this is a multi-class classification problem)\n",
    "oneh = True\n",
    "trainX, trainy, testX, testy, validX, validy = contacts_utils.split_data(X, y, validation_reqd)\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "\n",
    "# Now run the model with the best params\n",
    "best_model_nn = create_svm_model(trainX, trainy, testX, testy)\n",
    "st_ = timer()\n",
    "# run NN model in parallel and extract results (train_score, valid_score,parameter, history of fit) as a list\n",
    "b_train_score, b_val_score, b_param_dict, b_history, y_labels_predicted = best_model_nn(best_model_params)\n",
    "end_ = timer()\n",
    "\n",
    "accuracy, sensitivity, specificity, likelihood = contacts_utils.model_stats_all_labels(y_labels_predicted, testy)\n",
    "print(f'Accuracy of model(<3, = 3, >3) is:   {np.round(accuracy*100, 2)}%')\n",
    "print(f'Sensitivity of the test(<3, = 3, >3):{np.round(sensitivity*100,2)}%')\n",
    "print(f'Specificity of the test(<3, = 3, >3):{np.round(specificity*100,2)}%')\n",
    "print(f'Likelihood ratio(<3, = 3, >3):       {np.round(likelihood, 2)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7478654ab1aa58977e1af457aae5317775386ee06614bd651985e9aec83741b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}