{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bmukund/miniconda3/lib/python3.8/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package wordnet to /Users/bmukund/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/bmukund/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%timeit\n",
    "import sys\n",
    "sys.path.append('pymodules')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# this class read the raw input and tokenizes comprehensively for use with modeling\n",
    "import pymodules.read_and_tokenize as contacts_utils\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped: ['OVERALL_RATING', 'COMFORT_RATING', 'VISION_RATING', 'VALUE_FOR_MONEY', 'PROS', 'CONS', 'ORIGINAL_SOURCE', 'REPLY_FROM_ACCUVUE', 'PRODUCT_LINK', 'WEBSITE']\n",
      "Read sheet 'Scrubbed_data' ...\n",
      " Drop the Author column and replace it with gender of author ...\n",
      "Consolidate all the comments into one column called COMMENT\n",
      "Make ratings into integers\n",
      "Tokenize data based on regex found from experimentation and common usage ...\n",
      "Comments before tokenization at index[0]:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments after tokenization at index[0]:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] before basic cleaning:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] after cleaning:\n",
      " acucue 2 contact lenses i have used these lenses for a long time and i have to say that the service from lens.com is great and the lenses work great for my needs!  i highly recommend them!\n",
      "Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "\n",
      "['acucue', '2', 'contact', 'lenses', 'i', 'have', 'used', 'these', 'lenses', 'for', 'a', 'long', 'time', 'and', 'i', 'have', 'to', 'say', 'that', 'the', 'service', 'from', 'lens', '.', 'com', 'is', 'great', 'and', 'the', 'lenses', 'work', 'great', 'for', 'my', 'needs', '!', 'i', 'highly', 'recommend', 'them', '!']\n",
      "Comments at index[0] before removal of punctuations:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] after removal of punctuation:\n",
      " ['acucue', 'contact', 'lenses', 'have', 'used', 'these', 'lenses', 'for', 'long', 'time', 'and', 'have', 'say', 'that', 'the', 'service', 'from', 'lens', 'com', 'great', 'and', 'the', 'lenses', 'work', 'great', 'for', 'needs', 'highly', 'recommend', 'them']\n",
      "Comments at index[0] before removal of stop words:\n",
      " Acucue 2 Contact Lenses I have used these lenses for a long time and I have to say that the service from Lens.com is great and the lenses work great for my needs!  I highly recommend them!\n",
      "Comments at index[0] after removal of stop words:\n",
      " ['contact', 'used', 'time', 'service', 'com', 'great', 'work', 'great', 'needs', 'highly', 'recommend']\n",
      "Lemmatize tokens\n",
      "Comments at index[0] after lemmatization:\n",
      " ['contact', 'use', 'time', 'service', 'com', 'great', 'work', 'great', 'need', 'highly', 'recommend']\n",
      "Build the bigram and trigram words for use with topic modeling\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/Master-data_Q42021.xlsx\"\n",
    "prep_comments, df = contacts_utils.read_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Do we need bigrams ? Trigrams ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments at index[0] after addition of bigrams:\n",
      " ['contact', 'used', 'time', 'service', 'com', 'great', 'work', 'great', 'needs', 'highly', 'recommend', 'contact-used', 'used-time', 'time-service', 'service-com', 'com-great', 'great-work', 'work-great', 'great-needs', 'needs-highly', 'highly-recommend']\n",
      "Comments at index[-1] after addition of bigrams:\n",
      " ['buy', 'order', 'came', 'fast', 'without', 'issues', 'candy', 'nice', 'touch', 'buy-order', 'order-came', 'came-fast', 'fast-without', 'without-issues', 'issues-candy', 'candy-nice', 'nice-touch']\n"
     ]
    }
   ],
   "source": [
    "require_bigrams = True\n",
    "if require_bigrams:\n",
    "    for i in range(len(prep_comments.tokens)):\n",
    "        prep_comments.tokens[i] = prep_comments.tokens[i] + prep_comments.bigrams[i]\n",
    "\n",
    "test_index = 0\n",
    "print(f\"Comments at index[{test_index}] after addition of bigrams:\\n {prep_comments.tokens[test_index]}\")\n",
    "print(f\"Comments at index[{-1}] after addition of bigrams:\\n {prep_comments.tokens[-1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "8794"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prep_comments.tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vectorization\n",
    "* TF-IDF weights more words that occur frequently but in lesser number of documents. This seems to skew ranking towards advertisement like reviews. In any case for SVM, we use the count of tokens to establish a baseline accuracy of model, prior to using RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# simple auxiliary function to override the preprocessing done by sklearn\n",
    "def do_nothing(doc):\n",
    "    return doc\n",
    "\n",
    "# create a CountVectorizer object using our preprocessed text\n",
    "# uni gram\n",
    "count_vectorizer = CountVectorizer(encoding='utf-8',\n",
    "                                   preprocessor=do_nothing,  # apply no additional preprocessing\n",
    "                                   tokenizer=do_nothing,     # apply no additional tokenization\n",
    "                                   lowercase=False,\n",
    "                                   strip_accents=None,\n",
    "                                   stop_words=None,\n",
    "                                   ngram_range=(1, 1),       # generate only unigrams\n",
    "                                   analyzer='word',          # analysis at the word-level\n",
    "                                   #max_df=0.5,              # ignore tokens that have a higher document frequency (can be int or percent)\n",
    "                                   #min_df=500,                # ignore tokens that have a lowe document frequency (can be int or percent)\n",
    "                                   min_df=10,\n",
    "                                   max_features=None,        # we could impose a maximum number of vocabulary terms\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-term matrix created with shape: (8794, 1340)\n",
      "8794\n"
     ]
    }
   ],
   "source": [
    "# transform our preprocessed tokens into a document-term matrix\n",
    "dt_matrix = count_vectorizer.fit_transform(prep_comments.tokens)\n",
    "print(f\"Document-term matrix created with shape: {dt_matrix.shape}\")\n",
    "print(len(prep_comments.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                        0     1\n0                 contact   222\n1                    used  1222\n2                    time  1166\n3                 service  1051\n4                     com   165\n...                   ...   ...\n1335         vertex-toric  1239\n1336     preference-toric   901\n1337        vertex-sphere  1238\n1338  proclear-multifocal   937\n1339       proclear-toric   938\n\n[1340 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>contact</td>\n      <td>222</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>used</td>\n      <td>1222</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>time</td>\n      <td>1166</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>service</td>\n      <td>1051</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>com</td>\n      <td>165</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1335</th>\n      <td>vertex-toric</td>\n      <td>1239</td>\n    </tr>\n    <tr>\n      <th>1336</th>\n      <td>preference-toric</td>\n      <td>901</td>\n    </tr>\n    <tr>\n      <th>1337</th>\n      <td>vertex-sphere</td>\n      <td>1238</td>\n    </tr>\n    <tr>\n      <th>1338</th>\n      <td>proclear-multifocal</td>\n      <td>937</td>\n    </tr>\n    <tr>\n      <th>1339</th>\n      <td>proclear-toric</td>\n      <td>938</td>\n    </tr>\n  </tbody>\n</table>\n<p>1340 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can access a dictionary that maps between words and positions of the document-term matrix. We need this for SVM in order to make the word itself as column of dataframe (see output)\n",
    "id_word_indexer = pd.DataFrame(count_vectorizer.vocabulary_.items())\n",
    "id_word_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      contact  used  time  service  com  great  work  needs  highly  \\\n0           0     0     0        0    0      0     0      0       0   \n1           0     0     0        0    0      0     0      0       0   \n2           0     0     0        0    0      0     0      0       0   \n3           0     0     0        0    0      0     0      0       0   \n4           0     0     0        0    0      0     0      0       0   \n...       ...   ...   ...      ...  ...    ...   ...    ...     ...   \n8789        0     0     0        0    0      0     0      0       0   \n8790        0     0     0        0    0      0     0      0       0   \n8791        0     0     0        0    0      0     0      0       0   \n8792        0     0     0        0    0      0     0      0       0   \n8793        0     0     0        0    0      0     0      0       0   \n\n      recommend  ...  ultra-presbyopia  aspheric  frequency-aspheric  encore  \\\n0             0  ...                 0         0                   0       0   \n1             0  ...                 0         0                   0       0   \n2             0  ...                 0         0                   0       0   \n3             0  ...                 0         0                   0       0   \n4             0  ...                 0         0                   0       0   \n...         ...  ...               ...       ...                 ...     ...   \n8789          0  ...                 0         0                   0       0   \n8790          0  ...                 0         0                   0       0   \n8791          0  ...                 0         0                   0       0   \n8792          0  ...                 0         0                   0       0   \n8793          0  ...                 0         0                   0       0   \n\n      vertex  vertex-toric  preference-toric  vertex-sphere  \\\n0          0             0                 0              0   \n1          0             0                 0              0   \n2          0             0                 0              0   \n3          0             0                 0              0   \n4          0             0                 0              0   \n...      ...           ...               ...            ...   \n8789       0             0                 0              0   \n8790       0             0                 0              0   \n8791       0             0                 0              0   \n8792       0             0                 0              0   \n8793       0             0                 0              0   \n\n      proclear-multifocal  proclear-toric  \n0                       0               0  \n1                       0               0  \n2                       0               0  \n3                       0               0  \n4                       0               0  \n...                   ...             ...  \n8789                    0               0  \n8790                    0               0  \n8791                    0               0  \n8792                    0               0  \n8793                    0               0  \n\n[8794 rows x 1340 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contact</th>\n      <th>used</th>\n      <th>time</th>\n      <th>service</th>\n      <th>com</th>\n      <th>great</th>\n      <th>work</th>\n      <th>needs</th>\n      <th>highly</th>\n      <th>recommend</th>\n      <th>...</th>\n      <th>ultra-presbyopia</th>\n      <th>aspheric</th>\n      <th>frequency-aspheric</th>\n      <th>encore</th>\n      <th>vertex</th>\n      <th>vertex-toric</th>\n      <th>preference-toric</th>\n      <th>vertex-sphere</th>\n      <th>proclear-multifocal</th>\n      <th>proclear-toric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8789</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8790</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8791</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8792</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8793</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8794 rows × 1340 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FOR SVM, we need to make a matrix with proper column names\n",
    "# Also, we need another column that denotes the review\n",
    "# We also need to normalize the data\n",
    "df_svm = pd.DataFrame(dt_matrix.toarray())\n",
    "df_svm.rename(columns=id_word_indexer.to_dict()[0], inplace=True)\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            FINAL_PRODUCT_NAME  RATING  \\\nREVIEW_DATE                                                              \n2021-11-01   Acuvue 2 Contact Lenses                       ...       5   \n2021-12-02   Acuvue 2 Contact Lenses                       ...       4   \n2021-12-01   Acuvue 2 Contact Lenses                       ...       4   \n2021-11-16   Acuvue 2 Contact Lenses                       ...       5   \n2021-12-08   Acuvue 2 Contact Lenses                       ...       4   \n...                                                        ...     ...   \n2021-11-29   Acuvue VITA Contact Lenses                    ...       5   \n2021-11-23                Shop Acuvue Vita 12 pack  (1.0 Box )       5   \n2021-12-27          Acuvue Vita for Astigmatism Contact Lenses       5   \n2021-10-16          Acuvue Vita for Astigmatism Contact Lenses       1   \n2021-12-05          Acuvue Vita for Astigmatism Contact Lenses       5   \n\n             PRODUCT   BRAND   GENDER  \\\nREVIEW_DATE                             \n2021-11-01   Acuvue2  Acuvue     male   \n2021-12-02   Acuvue2  Acuvue   female   \n2021-12-01   Acuvue2  Acuvue   female   \n2021-11-16   Acuvue2  Acuvue     male   \n2021-12-08   Acuvue2  Acuvue  unknown   \n...              ...     ...      ...   \n2021-11-29      Vita  Acuvue     male   \n2021-11-23      Vita  Acuvue     male   \n2021-12-27      Vita  Acuvue     male   \n2021-10-16      Vita  Acuvue  unknown   \n2021-12-05      Vita  Acuvue   female   \n\n                                                       COMMENT  \nREVIEW_DATE                                                     \n2021-11-01   Acucue 2 Contact Lenses I have used these lens...  \n2021-12-02                      Clear vision Tends to cloud up  \n2021-12-01   comfort These are very hard to handle. Flimsy ...  \n2021-11-16   Easy to use I have been using this product for...  \n2021-12-08   Excellent Excellent got promised a discount of...  \n...                                                        ...  \n2021-11-29   Truly the Best The price, fast shipping,  quic...  \n2021-11-23   Very Comfortable Acuvue  Vita are very comfort...  \n2021-12-27   Very Comfortable and Convenient Very Comfortab...  \n2021-10-16   Worst lenses I've worn, microscopic tears in a...  \n2021-12-05   Would buy again My order came in fast without ...  \n\n[8794 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FINAL_PRODUCT_NAME</th>\n      <th>RATING</th>\n      <th>PRODUCT</th>\n      <th>BRAND</th>\n      <th>GENDER</th>\n      <th>COMMENT</th>\n    </tr>\n    <tr>\n      <th>REVIEW_DATE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-11-01</th>\n      <td>Acuvue 2 Contact Lenses                       ...</td>\n      <td>5</td>\n      <td>Acuvue2</td>\n      <td>Acuvue</td>\n      <td>male</td>\n      <td>Acucue 2 Contact Lenses I have used these lens...</td>\n    </tr>\n    <tr>\n      <th>2021-12-02</th>\n      <td>Acuvue 2 Contact Lenses                       ...</td>\n      <td>4</td>\n      <td>Acuvue2</td>\n      <td>Acuvue</td>\n      <td>female</td>\n      <td>Clear vision Tends to cloud up</td>\n    </tr>\n    <tr>\n      <th>2021-12-01</th>\n      <td>Acuvue 2 Contact Lenses                       ...</td>\n      <td>4</td>\n      <td>Acuvue2</td>\n      <td>Acuvue</td>\n      <td>female</td>\n      <td>comfort These are very hard to handle. Flimsy ...</td>\n    </tr>\n    <tr>\n      <th>2021-11-16</th>\n      <td>Acuvue 2 Contact Lenses                       ...</td>\n      <td>5</td>\n      <td>Acuvue2</td>\n      <td>Acuvue</td>\n      <td>male</td>\n      <td>Easy to use I have been using this product for...</td>\n    </tr>\n    <tr>\n      <th>2021-12-08</th>\n      <td>Acuvue 2 Contact Lenses                       ...</td>\n      <td>4</td>\n      <td>Acuvue2</td>\n      <td>Acuvue</td>\n      <td>unknown</td>\n      <td>Excellent Excellent got promised a discount of...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-11-29</th>\n      <td>Acuvue VITA Contact Lenses                    ...</td>\n      <td>5</td>\n      <td>Vita</td>\n      <td>Acuvue</td>\n      <td>male</td>\n      <td>Truly the Best The price, fast shipping,  quic...</td>\n    </tr>\n    <tr>\n      <th>2021-11-23</th>\n      <td>Shop Acuvue Vita 12 pack  (1.0 Box )</td>\n      <td>5</td>\n      <td>Vita</td>\n      <td>Acuvue</td>\n      <td>male</td>\n      <td>Very Comfortable Acuvue  Vita are very comfort...</td>\n    </tr>\n    <tr>\n      <th>2021-12-27</th>\n      <td>Acuvue Vita for Astigmatism Contact Lenses</td>\n      <td>5</td>\n      <td>Vita</td>\n      <td>Acuvue</td>\n      <td>male</td>\n      <td>Very Comfortable and Convenient Very Comfortab...</td>\n    </tr>\n    <tr>\n      <th>2021-10-16</th>\n      <td>Acuvue Vita for Astigmatism Contact Lenses</td>\n      <td>1</td>\n      <td>Vita</td>\n      <td>Acuvue</td>\n      <td>unknown</td>\n      <td>Worst lenses I've worn, microscopic tears in a...</td>\n    </tr>\n    <tr>\n      <th>2021-12-05</th>\n      <td>Acuvue Vita for Astigmatism Contact Lenses</td>\n      <td>5</td>\n      <td>Vita</td>\n      <td>Acuvue</td>\n      <td>female</td>\n      <td>Would buy again My order came in fast without ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8794 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2    8386\n0     336\n1      72\nName: _SENTIMENT_, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attach sentiment, seems\n",
    "def find_sentiment(rating):\n",
    "    choices = [0, 1, 2]\n",
    "    conditions = [rating < 3, rating == 3, rating > 3]\n",
    "    senti = np.select(conditions, choices)\n",
    "    return senti\n",
    "\n",
    "SENTIMENT_SERIES = df['RATING'].apply(find_sentiment).astype('category')\n",
    "df_svm['_SENTIMENT_'] = SENTIMENT_SERIES.values\n",
    "df_svm['_SENTIMENT_'] = df_svm['_SENTIMENT_'].astype('category')\n",
    "df_svm._SENTIMENT_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df_svm.drop(['_SENTIMENT_'], axis=1)\n",
    "y = df_svm['_SENTIMENT_']\n",
    "validation_reqd = True\n",
    "df_trainX, df_trainy, df_testX, df_testy, df_validX, df_validy = contacts_utils.split_data(X, y, validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Null accuracy\n",
    "This is the accuracy based on the proportion of input distribution of sentiment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy of sentiment rating < 3, corresponding to code 0 is: 3.821%\n",
      "Null accuracy of sentiment rating = 3, corresponding to code 0 is: 0.819%\n",
      "Null accuracy of sentiment rating > 3, corresponding to code 0 is: 95.36%\n"
     ]
    }
   ],
   "source": [
    "rating_counts = y.value_counts()\n",
    "dn = np.sum(rating_counts)\n",
    "\n",
    "null_rating_lt_3 = round((rating_counts[0]/dn)* 100, 3)\n",
    "null_rating_eq_3 = round((rating_counts[1]/dn)* 100, 3)\n",
    "null_rating_gt_3 = round((rating_counts[2]/dn)* 100, 3)\n",
    "print(f\"Null accuracy of sentiment rating < 3, corresponding to code 0 is: {null_rating_lt_3}%\")\n",
    "print(f\"Null accuracy of sentiment rating = 3, corresponding to code 0 is: {null_rating_eq_3}%\")\n",
    "print(f\"Null accuracy of sentiment rating > 3, corresponding to code 0 is: {null_rating_gt_3}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Normalize column data please ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "df_trainX = ss.fit_transform(df_trainX)\n",
    "df_testX = ss.fit_transform(df_testX)\n",
    "df_validX = ss.fit_transform(df_validX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167\n",
    "# How to choose C and gamma values ...\n",
    "# 0.0001 < gamma < 10\n",
    "# 0.1 < C < 100\n",
    "# When gamma is large, C does not matter ...\n",
    "\n",
    "def create_svm_model(trainX, trainy, validX, validy):\n",
    "    def _create_svm_model(param_dict):\n",
    "        C = param_dict['C']\n",
    "        kernel = param_dict['kernel']\n",
    "        degree = param_dict['degree']\n",
    "\n",
    "        model = SVC(C=C,\n",
    "                        kernel=kernel,\n",
    "                        degree=degree,\n",
    "                        gamma='auto',\n",
    "                        class_weight='balanced',\n",
    "                        random_state=42)\n",
    "\n",
    "\n",
    "        # fit model ...\n",
    "        history = model.fit(X=trainX, y=trainy)\n",
    "            #, validation_data = (validX,validy),\n",
    "            #                verbose=1,\n",
    "            #                workers=4,\n",
    "            #                use_multiprocessing=True)\n",
    "\n",
    "        y_pred_train = model.predict(trainX)#, workers=4, use_multiprocessing=True)\n",
    "        y_pred_validation = model.predict(validX)#, workers=4, use_multiprocessing=True)\n",
    "\n",
    "        #y_train_pred_labels = convert_prob_to_labels(y_pred_train)\n",
    "        #y_validation_pred_labels = convert_prob_to_labels(y_pred_validation)\n",
    "\n",
    "        # accuracy score used ...\n",
    "        train_score = accuracy_score(trainy, y_pred_train)\n",
    "        val_score = accuracy_score(validy, y_pred_validation)\n",
    "\n",
    "        return train_score, val_score, param_dict, history, y_pred_validation\n",
    "\n",
    "    return _create_svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters to be varied\n",
    "C = [1.0] #np.logspace(0, 1, 21)\n",
    "kernel_functions = ['linear'] #('linear', 'poly', 'rbf', 'sigmoid')\n",
    "degree_vals = [1]\n",
    "\n",
    "parameters = [{'C': C,\n",
    "              'kernel': kernel_functions,\n",
    "              'degree': degree_vals\n",
    "              }\n",
    "              ]\n",
    "\n",
    "# make a grid out of parameter choices ...\n",
    "grid_params = ParameterGrid(parameters)\n",
    "[print(x) for x in grid_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to finish best parameter search with SVM model: 0.28690618044999994 mins.\n"
     ]
    }
   ],
   "source": [
    "# func that sets up the context .. i.e. what the pipeline does, what the data input is\n",
    "svm_model_func = create_svm_model(df_trainX, df_trainy, df_validX, df_validy)\n",
    "\n",
    "st_ = timer()\n",
    "# run NN model in parallel and extract results (train_score, valid_score,parameter, history of fit) as a list\n",
    "results = contacts_utils.run_parallel(svm_model_func, num_cpus=4)(grid_params)\n",
    "\n",
    "end_ = timer()\n",
    "\n",
    "print(f\"Time taken to finish best parameter search with SVM model: {(end_-st_)/60.0} mins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Why SVM ? Why not LR, Naive Bayes as NULL model ?\n",
    "* LR ans SVM are closesly related. If the idea is to know the probabilities, then LR is a good option. But if the idea is to make the *right decision* (i.e. can be expressed as ratio of likelihoods), we end up with SVM method!\n",
    "* Naive Bayes assumes *class conditional independence*. In this context, this means, given the sentiments, the features found are independent of each other. This i not true for this problem.\n",
    "* LDA is very closely related to Naive Bayes with additional assumption of Gaussian distribution of features. So we can ignore this as well.\n",
    "* What about decision trees and its friends ?\n",
    "    * No proabilistic distribution assumption on response or features\n",
    "    * Can be used in offline mode, but with addition of new data, one needs to retrain from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.9306510311362718,\n  0.7853244390539721,\n  {'C': 1.0, 'degree': 1, 'kernel': 'linear'},\n  SVC(class_weight='balanced', degree=1, gamma='auto', kernel='linear',\n      random_state=42),\n  array([2, 0, 2, ..., 0, 2, 2]))]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score:0.7853244390539721\n",
      "Best params based on validation score:{'C': 1.0, 'degree': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters based on validation score\n",
    "best_validation_score = results[0][1]\n",
    "best_params = results[0][2]\n",
    "plot_data = results[0][3]\n",
    "best_validation_data = results[0][4]\n",
    "for i in range(1, len(results)):\n",
    "    tscore = results[i][0]\n",
    "    vscore = results[i][1]\n",
    "    param = results[i][2]\n",
    "    if vscore > best_validation_score:\n",
    "        best_validation_score = vscore\n",
    "        best_params = param\n",
    "        plot_data = results[i][3]\n",
    "        best_validation_data = results[i][4]\n",
    "\n",
    "# output result\n",
    "print(f\"Best validation score:{best_validation_score}\")\n",
    "print(f\"Best params based on validation score:{best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.04      0.28      0.08        32\n",
      "     neutral       0.01      0.17      0.01         6\n",
      "    positive       0.98      0.80      0.88      1611\n",
      "\n",
      "    accuracy                           0.79      1649\n",
      "   macro avg       0.35      0.42      0.32      1649\n",
      "weighted avg       0.96      0.79      0.86      1649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "targetnames=['negative', 'neutral', 'positive']\n",
    "#y_pred =   np.argmax(y_pred_raw, axis = 1)\n",
    "#y_true = np.argmax(y_test, axis = 1)\n",
    "print(metrics.classification_report(df_validy, best_validation_data, target_names=targetnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   9    5   18]\n",
      " [   3    1    2]\n",
      " [ 191  135 1285]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# multi-label plot ...\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(df_validy, best_validation_data)\n",
    "print(cm)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multi label stats\n",
    "This function extracts Accuracy, Sensitivity, Specificity and Likelihood ratio for each of the 3 sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model(<3, = 3, >3) is:   [86.84 91.21 79.02]%\n",
      "Sensitivity of the test(<3, = 3, >3):[28.12 16.67 79.76]%\n",
      "Specificity of the test(<3, = 3, >3):[88.   91.48 47.37]%\n",
      "Likelihood ratio(<3, = 3, >3):       [2.34 1.96 1.52]\n"
     ]
    }
   ],
   "source": [
    "accuracy, sensitivity, specificity, likelihood = contacts_utils.model_stats_all_labels(best_validation_data, df_validy)\n",
    "print(f'Accuracy of model(<3, = 3, >3) is:   {np.round(accuracy*100, 2)}%')\n",
    "print(f'Sensitivity of the test(<3, = 3, >3):{np.round(sensitivity*100,2)}%')\n",
    "print(f'Specificity of the test(<3, = 3, >3):{np.round(specificity*100,2)}%')\n",
    "print(f'Likelihood ratio(<3, = 3, >3):       {np.round(likelihood, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(6595, 1340), y=(6595,)\n",
      "Test: X=(2199, 1340), y=(2199,)\n",
      "Accuracy of model(<3, = 3, >3) is:   [89.63 98.45 88.63]%\n",
      "Sensitivity of the test(<3, = 3, >3):[57.83 44.44 89.94]%\n",
      "Specificity of the test(<3, = 3, >3):[90.88 98.9  61.39]%\n",
      "Likelihood ratio(<3, = 3, >3):       [ 6.34 40.39  2.33]\n"
     ]
    }
   ],
   "source": [
    "# We extract the best params from above cells\n",
    "best_model_params = best_params\n",
    "\n",
    "# Instead of joining validation data and train data, we simply reload the original data and split then into\n",
    "# train and test. This is suboptimal, but being relatively fast, this is ok for now\n",
    "validation_reqd = False\n",
    "# we want the output to be onehot encoded and this makes it easier to use other activation functions\n",
    "# other than softmax for the last layer, (as this is a multi-class classification problem)\n",
    "oneh = True\n",
    "trainX, trainy, testX, testy, validX, validy = contacts_utils.split_data(X, y, validation_reqd)\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "\n",
    "# Now run the model with the best params\n",
    "best_model_nn = create_svm_model(trainX, trainy, testX, testy)\n",
    "st_ = timer()\n",
    "# run NN model in parallel and extract results (train_score, valid_score,parameter, history of fit) as a list\n",
    "b_train_score, b_val_score, b_param_dict, b_history, y_labels_predicted = best_model_nn(best_model_params)\n",
    "end_ = timer()\n",
    "\n",
    "accuracy, sensitivity, specificity, likelihood = contacts_utils.model_stats_all_labels(y_labels_predicted, testy)\n",
    "print(f'Accuracy of model(<3, = 3, >3) is:   {np.round(accuracy*100, 2)}%')\n",
    "print(f'Sensitivity of the test(<3, = 3, >3):{np.round(sensitivity*100,2)}%')\n",
    "print(f'Specificity of the test(<3, = 3, >3):{np.round(specificity*100,2)}%')\n",
    "print(f'Likelihood ratio(<3, = 3, >3):       {np.round(likelihood, 2)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7478654ab1aa58977e1af457aae5317775386ee06614bd651985e9aec83741b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}