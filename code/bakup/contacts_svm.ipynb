{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%timeit\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import sys\n",
    "from collections import Counter\n",
    "import random\n",
    "import ast\n",
    "import re\n",
    "import scipy\n",
    "\n",
    "sys.path.append('pymodules')\n",
    "\n",
    "# This class contains some utility functions Word2Vec, stop words etc. etc.\n",
    "import pymodules.preprocessing_class as pc\n",
    "\n",
    "# this class read the raw input and tokenizes comprehensively for use with modeling\n",
    "import pymodules.read_and_tokenize as contacts_file_reader\n",
    "\n",
    "# gender gueser\n",
    "import gender_guesser.detector as gd\n",
    "\n",
    "# for dictionary method synonym finder using wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# (VII)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# model/ensemble scorer ...\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "##########\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score\n",
    "# model/ensemble scorer ...\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import multiprocess as mp\n",
    "\n",
    "# from https://stackoverflow.com/questions/7370801/how-do-i-measure-elapsed-time-in-python\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_wordnet_synonyms(word_list, type_of_word=None):\n",
    "    \"\"\" it is assumed that the word_list words are themselves synonyms and is given as a list (even if there is only one word\n",
    "    return lemmatized synonyms ...\n",
    "    \"\"\"\n",
    "    synonyms = set()\n",
    "    for word_to_look in word_list:\n",
    "        #print(f\"looking for synonyms of word:{word_to_look}\")\n",
    "        for syn in wn.synsets(word_to_look, pos=type_of_word):\n",
    "            for i in syn.lemmas():\n",
    "                synonyms.add(i.name())\n",
    "    #print(f\"Synonyms:\\n {synonyms}\")\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get the first name so that we can guess the gender\n",
    "def first_name(x):\n",
    "    \"\"\"\n",
    "    We determine the first name from the given string. We also remove any digits from the name. \n",
    "    Further, we use space to split names\n",
    "    \"\"\"\n",
    "    x_split = str(x).split()\n",
    "    fname = x_split[0]\n",
    "    # remove reference to digits. Now after removal, there could be some misclassification, but that is ok ..\n",
    "    fname_p = re.sub(r'[0-9]+', \"\", fname)\n",
    "    ret_str = fname_p.capitalize()\n",
    "    return ret_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for parallel run of multiple trials ...\n",
    "def run_parallel(func, num_cpus=4):\n",
    "    \"\"\"\n",
    "    A simple parallel processor\n",
    "    \"\"\"\n",
    "    mp_pool = mp.Pool(num_cpus)\n",
    "\n",
    "    def _run(grid_parameters):\n",
    "        result = mp_pool.map(func, grid_parameters)\n",
    "        return result\n",
    "\n",
    "    return _run\n",
    "\n",
    "\n",
    "# Ref: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/\n",
    "def onehot_encode(data):\n",
    "    \"\"\"\n",
    "    one hot encoding for CNN\n",
    "    \"\"\"\n",
    "    return to_categorical(data)\n",
    "\n",
    "\n",
    "# load dataset\n",
    "def split_data(X, y, validation=False, shuffle=False):\n",
    "    \"\"\"\n",
    "    load data and create validation set as well (25% of training data)\n",
    "    \"\"\"\n",
    "    trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=shuffle)\n",
    "    # create validation data as well\n",
    "    if validation:\n",
    "        trainX, validX, trainy, validy = train_test_split(trainX, trainy, test_size=0.25, random_state=42,\n",
    "                                                          shuffle=shuffle)\n",
    "        return trainX, trainy, testX, testy, validX, validy\n",
    "    else:\n",
    "        return trainX, trainy, testX, testy, None, None\n",
    "\n",
    "\n",
    "def plot_accuracy(model, test_str='Validation'):\n",
    "    plt.plot(model.history['accuracy'])\n",
    "    plt.plot(model.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', test_str], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(model, test_str='Validation'):\n",
    "    plt.plot(model.history['loss'])\n",
    "    plt.plot(model.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', test_str], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_prob_to_labels(data):\n",
    "    # the outputs are probabilities, change it to classifier labels ..\n",
    "    y_arg = np.argmax(data, axis=1)\n",
    "    y_pred = onehot_encode(y_arg)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def model_stats_all_labels(Y_pred, Y_actual):\n",
    "    # true negatives is  C[0, 0]\n",
    "    # false negatives is C[1, 0]\n",
    "    # true positives is  C[1, 1]\n",
    "    # false positives is C[0, 1]\n",
    "    mcm = multilabel_confusion_matrix(Y_actual, Y_pred)\n",
    "    tnv = mcm[:, 0, 0]\n",
    "    tpv = mcm[:, 1, 1]\n",
    "    fnv = mcm[:, 1, 0]\n",
    "    fpv = mcm[:, 0, 1]\n",
    "\n",
    "    accuracy = (tpv + tnv) / (tpv + tnv + fpv + fnv)\n",
    "    sensitivity = tpv / (tpv + fnv)\n",
    "    specificity = tnv / (tnv + fpv)\n",
    "    denom = 1 - specificity\n",
    "    likelihood = [sensitivity[i] / denom[i] if denom[i] > 0 else np.nan for i in range(len(denom))]\n",
    "\n",
    "    return accuracy, sensitivity, specificity, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"data/Master-data_Q42021.xlsx\"\n",
    "text_data_raw = pd.read_excel(filename, sheet_name='Scrubbed_data', index_col='REVIEW_DATE')\n",
    "\n",
    "# We don't need these columns\n",
    "not_needed = ['OVERALL_RATING', 'COMFORT_RATING', 'VISION_RATING', 'VALUE_FOR_MONEY', 'PROS', 'CONS', 'ORIGINAL_SOURCE', 'REPLY_FROM_ACCUVUE',\n",
    "'PRODUCT_LINK', 'WEBSITE']\n",
    "\n",
    "text_data = text_data_raw.drop(columns = not_needed, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let us figure out the gender from the names and drop the names column\n",
    "# We use gender_guesser package.\n",
    "#text_data['AUTHOR'] = text_data['AUTHOR'].astype(str)\n",
    "gdx = gd.Detector()\n",
    "text_data['GENDER'] = text_data.AUTHOR.apply(first_name).map(lambda x: gdx.get_gender(x))\n",
    "\n",
    "# Drop the author column now\n",
    "text_data.drop(columns = ['AUTHOR'], axis=1, inplace=True)\n",
    "\n",
    "# Check the gender counts just to see how the data looks like\n",
    "text_data.GENDER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Consolidate the comments into one column\n",
    "# Comments can occur both in title and in Comment columns. \n",
    "text_data['COMMENT'] = text_data['TITLE'].astype(str).fillna(\"\") + \" \" + text_data['COMMENTS'].astype(str).fillna(\"\")\n",
    "text_data.drop(columns = ['TITLE', 'COMMENTS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clean rating\n",
    "# replace N = No rating with 0. We do this because rating is assumed to be numeric, not categorical\n",
    "text_data['RATING'].replace('N', '0', inplace=True)\n",
    "# convert rating to integers\n",
    "text_data['RATING'] = text_data['RATING'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# display results\n",
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## regex for tokenization\n",
    "# Ref: http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py\n",
    "emoticon_string = r\"\"\"\n",
    "    (?:\n",
    "      [<>]?\n",
    "      [:;=8]                     # eyes\n",
    "      [\\-o\\*\\']?                 # optional nose\n",
    "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "      |\n",
    "      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "      [\\-o\\*\\']?                 # optional nose\n",
    "      [:;=8]                     # eyes\n",
    "      [<>]?\n",
    "    )\"\"\"\n",
    "\n",
    "# The components of the tokenizer:\n",
    "regex_strings = (\n",
    "    # Phone numbers:\n",
    "    r\"\"\"\n",
    "    (?:\n",
    "      (?:            # (international)\n",
    "        \\+?[01]\n",
    "        [\\-\\s.]*\n",
    "      )?\n",
    "      (?:            # (area code)\n",
    "        [\\(]?\n",
    "        \\d{3}\n",
    "        [\\-\\s.\\)]*\n",
    "      )?\n",
    "      \\d{3}          # exchange\n",
    "      [\\-\\s.]*\n",
    "      \\d{4}          # base\n",
    "    )\"\"\"\n",
    "    ,\n",
    "    # Emoticons:\n",
    "    emoticon_string\n",
    "    ,\n",
    "    # HTML tags:\n",
    "    r\"\"\"<[^>]+>\"\"\"\n",
    "    ,\n",
    "    # Twitter username:\n",
    "    r\"\"\"(?:@[\\w_]+)\"\"\"\n",
    "    ,\n",
    "    # Twitter hashtags:\n",
    "    r\"\"\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\"\"\"\n",
    "    ,\n",
    "    # Remaining word types:\n",
    "    r\"\"\"\n",
    "    (?:[a-z][a-z'\\-_]+[a-z])       # Words with apostrophes or dashes.\n",
    "    |\n",
    "    (?:[+\\-]?\\d+[,/.:-]\\d+[+\\-]?)  # Numbers, including fractions, decimals.\n",
    "    |\n",
    "    (?:[\\w_]+)                     # Words without apostrophes or dashes.\n",
    "    |\n",
    "    (?:\\.(?:\\s*\\.){1,})            # Ellipsis dots.\n",
    "    |\n",
    "    (?:\\S)                         # Everything else that isn't whitespace.\n",
    "    \"\"\",\n",
    "    r\"\"\"\n",
    "    (?x)                # set flag to allow verbose regexps (to separate logical sections of pattern and add comments)\n",
    "    \\w+(?:-\\w+)*        # preserve expressions with internal hyphens as single tokens\n",
    "    | [][.,;\"'?():-_`]  # preserve punctuation as separate tokens\n",
    "    \"\"\"\n",
    ")\n",
    "word_re = re.compile(pattern=r\"\"\"(%s)\"\"\" % \"|\".join(regex_strings), flags=re.VERBOSE | re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comments_data = text_data.COMMENT\n",
    "prep_comments = pc.RawDocs(comments_data,  # series of documents\n",
    "                  lower_case=True,  # whether to lowercase the text in the firs cleaning step\n",
    "                  stopwords='long',  # type of stopwords to initialize\n",
    "                  contraction_split=True,  # wheter to split contractions or not\n",
    "                  tokenization_pattern=word_re  # custom tokenization patter\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# notice that the documents from the object are identical to the ones from the pandas series\n",
    "#comments_data\n",
    "i = 0\n",
    "print(\"Document from the pandas series:\\n\", comments_data[i])\n",
    "print(\"\\n-------------------------\\n\")\n",
    "print(\"Document from preprocessing object:\\n\", prep_comments.docs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lower-case text, expand contractions and initialize stopwords list\n",
    "prep_comments.basic_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# explore an example after the basic cleaning has been applied\n",
    "i = 0\n",
    "print(comments_data[i])\n",
    "print()\n",
    "print(prep_comments.docs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now we can split the documents into tokens\n",
    "prep_comments.tokenize_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(comments_data[i])\n",
    "print()\n",
    "print(prep_comments.tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "punctuation = punctuation.replace(\"-\", \"\") # remove the hyphen from the punctuation string\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prep_comments.token_clean(length=2,                 # remove tokens with less than this number of characters\n",
    "                 punctuation=punctuation,           # remove custom list of punctuation characters\n",
    "                 numbers = True                     # remove numbers\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(comments_data[i])\n",
    "print()\n",
    "print(prep_comments.tokens[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the list of stopwords provided earlier\n",
    "print(sorted(prep_comments.stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we need to specificy that we want to remove the stopwords from the \"tokens\"\n",
    "prep_comments.stopword_remove('tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(comments_data[i])\n",
    "print()\n",
    "print(prep_comments.tokens[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# stemming\n",
    "# pre_comments.stem()\n",
    "\n",
    "# apply lemmatization to all documents (takes a very long time so we will avoid it for now)\n",
    "prep_comments.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compare all versions of the same raw sentences\n",
    "i = 0\n",
    "print(comments_data[i])\n",
    "print()\n",
    "print(prep_comments.tokens[i])\n",
    "print()\n",
    "# print(prep_comments.stems[i])\n",
    "# print()\n",
    "print(prep_comments.lemmas[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prep_comments.get_term_ranking(items='tokens', score_type='df')\n",
    "prep_comments.df_ranking['tokens'][:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TF-IDF weights more words that occur frequently but in less number of documents. This seems to skew ranking towards advertisement like reviews. (See output) It is not clear if such counting is relevant for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prep_comments.get_term_ranking(items='tokens', score_type='tfidf')\n",
    "prep_comments.tfidf_ranking['tokens'][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prep_comments.df_ranking['tokens'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prep_comments.tfidf_ranking['tokens'][-15:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([x[0] for x in prep_comments.df_ranking['tokens']])\n",
    "plt.title('Document frequency ranking')\n",
    "plt.ylabel(\"Document frequency\")\n",
    "plt.xlabel(\"Term ranking\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we can use a log-log scale to observe more clearly the power-law distribution (Zipf's law)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.loglog([x[0] for x in prep_comments.df_ranking['tokens']])\n",
    "plt.title('Document frequency ranking (log-log)')\n",
    "plt.ylabel(\"log document frequency\")\n",
    "plt.xlabel(\"log term ranking\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([x[0] for x in prep_comments.tfidf_ranking['tokens']])\n",
    "plt.title('Tf-idf ranking')\n",
    "plt.ylabel(\"tf-idf\")\n",
    "plt.xlabel(\"Term ranking\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# simple auxiliary function to override the preprocessing done by sklearn\n",
    "def do_nothing(doc):\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a CountVectorizer object using our preprocessed text\n",
    "count_vectorizer = CountVectorizer(encoding='utf-8',\n",
    "                                   preprocessor=do_nothing,  # apply no additional preprocessing\n",
    "                                   tokenizer=do_nothing,     # apply no additional tokenization\n",
    "                                   lowercase=False,\n",
    "                                   strip_accents=None,\n",
    "                                   stop_words=None,\n",
    "                                   ngram_range=(1, 1),       # generate only unigrams\n",
    "                                   analyzer='word',          # analysis at the word-level\n",
    "                                   max_df=0.5,              # ignore tokens that have a higher document frequency (can be int or percent)\n",
    "                                   min_df=500,                # ignore tokens that have a lowe document frequency (can be int or percent)\n",
    "                                   max_features=None,        # we could impose a maximum number of vocabulary terms\n",
    "                                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# transform our preprocessed tokens into a document-term matrix\n",
    "dt_matrix = count_vectorizer.fit_transform(prep_comments.tokens)\n",
    "print(f\"Document-term matrix created with shape: {dt_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we can access a dictionary that maps between words and positions of the document-term matrix\n",
    "# list(count_vectorizer.vocabulary_.items())[0:10]\n",
    "id_word_indexer = pd.DataFrame(count_vectorizer.vocabulary_.items())\n",
    "id_word_indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dictionary methods\n",
    "Dictionary methods ai to find synonyms of words and add to the corpus. In our case we want to classify our corpus based on these four terms by identifying synonyms from the text\n",
    "* Identify \"product\"\n",
    "* Identify \"service\"\n",
    "* Identify \"quality\"\n",
    "* Identify \"price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Finding synonyms using WordNet for the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "product_words = ['gadget', 'contraption', 'appliance', 'widget', 'equipment', 'contrivance', 'gizmo', 'product', 'merchandise', 'ware', 'gismo']\n",
    "service_words = ['service', 'assist', 'help', 'aid']\n",
    "quality_words = ['quality', 'built', 'refurbish', 'comfort', 'relief']\n",
    "price_words = ['price', 'money', 'cash', 'cheap', 'costly', 'pricey', 'discount', 'payment', 'rebate', 'cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Now we use the synonym finder to generate extra set of words for identifying classification words.\n",
    "We then use the resulting set of words as tokens to be found in our corpus. Because the synonym words from the wordnet synonym finder may not be entirely suitable to be used automatically\n",
    "we filter the result. Particularly, some words could be used in different senses (noun, adjective etc.) and could determine different classification. Given that we know the domain here,\n",
    "we want to make sure that the synonyms we find don't add to the ambiguity\n",
    "For example, one of the synonyms for \"ware\" is \"convenience\" (as in mode of convenience). But this could also mean \"ease of use\", which would come under \"quality\" and not under \"product\"\n",
    "In order to avoid this, we manually filter out the output synonyms of wordnet results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "syns_indicating_product = find_wordnet_synonyms(product_words, wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "syns_indicating_service = find_wordnet_synonyms(service_words, wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "syns_indicating_quality = find_wordnet_synonyms(quality_words, wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "syns_indicating_price = find_wordnet_synonyms(price_words, wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokens_indicating_product = product_words\n",
    "tokens_indicating_service = service_words\n",
    "tokens_indicating_quality = quality_words\n",
    "tokens_indicating_price = price_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vocabulary's key is the feature word and the value is the feature-word's index in the feature column ...\n",
    "service_indicator_token_ids = [v for k,v in count_vectorizer.vocabulary_.items() if k in tokens_indicating_service]\n",
    "print(f\"{len(service_indicator_token_ids)} tokens found in vocabulary indicating service, {service_indicator_token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "product_indicator_token_ids = [v for k,v in count_vectorizer.vocabulary_.items() if k in tokens_indicating_product]\n",
    "print(f\"{len(product_indicator_token_ids)} tokens found in vocabulary indicating product, {product_indicator_token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quality_indicator_token_ids = [v for k,v in count_vectorizer.vocabulary_.items() if k in tokens_indicating_quality]\n",
    "print(f\"{len(quality_indicator_token_ids)} tokens found in vocabulary indicating quality, {quality_indicator_token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "price_indicator_token_ids = [v for k,v in count_vectorizer.vocabulary_.items() if k in tokens_indicating_price]\n",
    "print(f\"{len(price_indicator_token_ids)} tokens found in vocabulary indicating price, {price_indicator_token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "service_indicator_counts = dt_matrix.tocsr()[:, service_indicator_token_ids]\n",
    "# for a given data, count all such tokens that indicate service and presumably, one can add this as a new column to the data itself\n",
    "service_indicator_counts = service_indicator_counts.sum(axis=1)\n",
    "service_indicator_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "product_indicator_counts = dt_matrix.tocsr()[:, product_indicator_token_ids]\n",
    "# for a given data, count all such tokens that indicate product and presumably, one can add this as a new column to the data itself\n",
    "product_indicator_counts = product_indicator_counts.sum(axis=1)\n",
    "np.array(product_indicator_counts).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "price_indicator_counts = dt_matrix.tocsr()[:, price_indicator_token_ids]\n",
    "# for a given data, count all such tokens that indicate price and presumably, one can add this as a new column to the data itself\n",
    "price_indicator_counts = price_indicator_counts.sum(axis=1)\n",
    "np.array(price_indicator_counts).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quality_indicator_counts = dt_matrix.tocsr()[:, quality_indicator_token_ids]\n",
    "# for a given data, count all such tokens that indicate quality and presumably, one can add this as a new column to the data itself\n",
    "quality_indicator_counts = quality_indicator_counts.sum(axis=1)\n",
    "np.array(quality_indicator_counts).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# index 14 - service, 15-product, 16-quality, 17-price\n",
    "for idx in [14, 15, 16, 17]:\n",
    "    unique, counts = np.unique(dt_matrix.toarray()[:, idx], return_counts=True)\n",
    "    print(f\"Index:{idx}, value:\\n{np.asarray((unique, counts)).T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_data['service'] = np.array(service_indicator_counts).ravel()\n",
    "text_data['product'] = np.array(product_indicator_counts).ravel()\n",
    "text_data['quality'] = np.array(quality_indicator_counts).ravel()\n",
    "text_data['price'] = np.array(price_indicator_counts).ravel()\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_data['RATING'].replace('N', '-1', inplace=True)\n",
    "text_data.RATING.value_counts()\n",
    "text_data['RATING'] = text_data['RATING'].apply(lambda x: int(x))\n",
    "\n",
    "data_agg = text_data.groupby(['price'], as_index=False).agg({'COMMENT': 'sum', 'RATING':'mean'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_agg = text_data.groupby(['service'], as_index=False).agg({'COMMENT': 'sum', 'RATING':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## FOR SVM, we need to make a matrix with proper column names\n",
    "# Also, we need another column that denotes the review\n",
    "# We also need to normalize the data\n",
    "df_svm = pd.DataFrame(dt_matrix.toarray())\n",
    "df_svm.rename(columns=id_word_indexer.to_dict()[0], inplace=True)\n",
    "df_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# attach sentiment, seems\n",
    "def find_sentiment(rating):\n",
    "    choices = [0, 1, 2]\n",
    "    conditions = [rating < 3, rating == 3, rating > 3]\n",
    "    senti = np.select(conditions, choices)\n",
    "    return senti\n",
    "\n",
    "SENTIMENT_SERIES = text_data['RATING'].apply(find_sentiment).astype('category')\n",
    "df_svm['_SENTIMENT_'] = SENTIMENT_SERIES.values\n",
    "#df_svm._SENTIMENT_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df_svm.drop(['_SENTIMENT_'], axis=1)\n",
    "y = df_svm['_SENTIMENT_']\n",
    "validation_reqd = True\n",
    "df_trainX, df_trainy, df_testX, df_testy, df_validX, df_validy = split_data(X, y, validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Normalize column data please ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "df_trainX = ss.fit_transform(df_trainX)\n",
    "df_testX = ss.fit_transform(df_testX)\n",
    "df_validX = ss.fit_transform(df_validX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_svm_model(trainX, trainy, validX, validy):\n",
    "    def _create_svm_model(param_dict):\n",
    "        C = param_dict['C']\n",
    "        kernel = param_dict['kernel']\n",
    "        degree = param_dict['degree']\n",
    "\n",
    "        model = SVC(C=C,\n",
    "                        kernel=kernel,\n",
    "                        degree=degree,\n",
    "                        gamma='auto',\n",
    "                        class_weight='balanced',\n",
    "                        random_state=42)\n",
    "\n",
    "\n",
    "        # fit model ...\n",
    "        history = model.fit(X=trainX, y=trainy)\n",
    "            #, validation_data = (validX,validy),\n",
    "            #                verbose=1,\n",
    "            #                workers=4,\n",
    "            #                use_multiprocessing=True)\n",
    "\n",
    "        y_pred_train = model.predict(trainX)#, workers=4, use_multiprocessing=True)\n",
    "        y_pred_validation = model.predict(validX)#, workers=4, use_multiprocessing=True)\n",
    "\n",
    "        #y_train_pred_labels = convert_prob_to_labels(y_pred_train)\n",
    "        #y_validation_pred_labels = convert_prob_to_labels(y_pred_validation)\n",
    "\n",
    "        # accuracy score used ...\n",
    "        train_score = accuracy_score(trainy, y_pred_train)\n",
    "        val_score = accuracy_score(validy, y_pred_validation)\n",
    "\n",
    "        return train_score, val_score, param_dict, history, y_pred_validation\n",
    "\n",
    "    return _create_svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parameters to be varied\n",
    "C = [1.0] #np.logspace(0, 1, 21)\n",
    "kernel_functions = ['linear'] #('linear', 'poly', 'rbf', 'sigmoid')\n",
    "degree_vals = [1]\n",
    "\n",
    "parameters = [{'C': C,\n",
    "              'kernel': kernel_functions,\n",
    "              'degree': degree_vals\n",
    "              }\n",
    "              ]\n",
    "\n",
    "# make a grid out of parameter choices ...\n",
    "grid_params = ParameterGrid(parameters)\n",
    "[print(x) for x in grid_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# func that sets up the context .. i.e. what the pipeline does, what the data input is\n",
    "svm_model_func = create_svm_model(df_trainX, df_trainy, df_validX, df_validy)\n",
    "\n",
    "st_ = timer()\n",
    "# run NN model in parallel and extract results (train_score, valid_score,parameter, history of fit) as a list\n",
    "results = run_parallel(svm_model_func, num_cpus=4)(grid_params)\n",
    "\n",
    "end_ = timer()\n",
    "\n",
    "print(f\"Time taken to finish best parameter search with SVM model: {(end_-st_)/60.0} mins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Why SVM ? Why not LR, Naive Bayes as NULL model ?\n",
    "* LR ans SVM are closesly related. If the idea is to know the probabilities, then LR is a good option. But if the idea is to make the *right decision* (i.e. can be expressed as ratio of likelihoods), we end up with SVM method!\n",
    "* Naive Bayes assumes *class conditional independence*. In this context, this means, given the sentiments, the features found are independent of each other. This i not true for this problem.\n",
    "* LDA is very closely related to Naive Bayes with additional assumption of Gaussian distribution of features. So we can ignore this as well.\n",
    "* What about decision trees and its friends ?\n",
    "    * No proabilistic distribution assumption on response or features\n",
    "    * Can be used in offline mode, but with addition of new data, one needs to retrain from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# find the best parameters based on validation score\n",
    "best_validation_score = results[0][1]\n",
    "best_params = results[0][2]\n",
    "plot_data = results[0][3]\n",
    "validation_data = results[0][4]\n",
    "for i in range(1, len(results)):\n",
    "    tscore = results[i][0]\n",
    "    vscore = results[i][1]\n",
    "    param = results[i][2]\n",
    "    if vscore > best_validation_score:\n",
    "        best_validation_score = vscore\n",
    "        best_params = param\n",
    "        plot_data = results[i][3]\n",
    "        validation_data = results[i][4]\n",
    "\n",
    "# output result\n",
    "print(f\"Best validation score:{best_validation_score}\")\n",
    "print(f\"Best params based on validation score:{best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#y_pred =   np.argmax(y_pred_raw, axis = 1)\n",
    "#y_true = np.argmax(y_test, axis = 1)\n",
    "print(metrics.classification_report(validation_data, df_validy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7478654ab1aa58977e1af457aae5317775386ee06614bd651985e9aec83741b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}